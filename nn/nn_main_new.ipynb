{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-07-15T16:25:06.740034Z",
     "start_time": "2023-07-15T15:52:48.814273Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM_attention(\n",
      "  (embedding): Embedding(54848, 50)\n",
      "  (encoder): LSTM(50, 100, num_layers=2, batch_first=True, dropout=0.25, bidirectional=True)\n",
      "  (decoder1): Linear(in_features=200, out_features=100, bias=True)\n",
      "  (decoder2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [01:00<00:00,  5.18it/s, log={'train_loss: 0.57503,train_acc:68.532%,F1: 80.556%,Recall:80.000%'}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val accuracy : 77.065%,val_loss:42.529, F1_score：80.328%, Recall：80.328%\n",
      "nn_models/nn_model_epoch_0.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [01:04<00:00,  4.87it/s, log={'train_loss: 0.46501,train_acc:77.748%,F1: 73.092%,Recall:73.333%'}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val accuracy : 78.149%,val_loss:41.055, F1_score：73.770%, Recall：73.770%\n",
      "nn_models/nn_model_epoch_1.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:59<00:00,  5.24it/s, log={'train_loss: 0.43751,train_acc:79.243%,F1: 70.505%,Recall:70.000%'}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val accuracy : 78.966%,val_loss:39.505, F1_score：73.610%, Recall：73.770%\n",
      "nn_models/nn_model_epoch_2.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [01:02<00:00,  5.00it/s, log={'train_loss: 0.41431,train_acc:80.983%,F1: 73.333%,Recall:73.333%'}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val accuracy : 79.837%,val_loss:39.230, F1_score：86.885%, Recall：86.885%\n",
      "nn_models/nn_model_epoch_3.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [01:03<00:00,  4.95it/s, log={'train_loss: 0.38724,train_acc:82.688%,F1: 69.766%,Recall:70.000%'}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val accuracy : 81.098%,val_loss:37.692, F1_score：86.892%, Recall：86.885%\n",
      "nn_models/nn_model_epoch_4.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [01:01<00:00,  5.08it/s, log={'train_loss: 0.36450,train_acc:84.233%,F1: 69.486%,Recall:70.000%'}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val accuracy : 81.133%,val_loss:37.098, F1_score：73.470%, Recall：73.770%\n",
      "nn_models/nn_model_epoch_5.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [01:01<00:00,  5.10it/s, log={'train_loss: 0.33869,train_acc:85.454%,F1: 90.034%,Recall:90.000%'}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val accuracy : 81.489%,val_loss:36.460, F1_score：90.276%, Recall：90.164%\n",
      "nn_models/nn_model_epoch_6.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:58<00:00,  5.35it/s, log={'train_loss: 0.31849,train_acc:86.364%,F1: 86.481%,Recall:86.667%'}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val accuracy : 81.116%,val_loss:38.118, F1_score：81.770%, Recall：81.967%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [01:00<00:00,  5.18it/s, log={'train_loss: 0.23583,train_acc:90.919%,F1: 90.082%,Recall:90.000%'}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val accuracy : 81.347%,val_loss:40.877, F1_score：85.278%, Recall：85.246%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [01:01<00:00,  5.05it/s, log={'train_loss: 0.21789,train_acc:91.584%,F1: 96.686%,Recall:96.667%'}]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val accuracy : 82.874%,val_loss:38.405, F1_score：80.328%, Recall：80.328%\n",
      "nn_models/nn_model_epoch_12.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:59<00:00,  5.30it/s, log={'train_loss: 0.20222,train_acc:92.304%,F1: 100.000%,Recall:100.000%'}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val accuracy : 82.768%,val_loss:38.622, F1_score：81.938%, Recall：81.967%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:59<00:00,  5.30it/s, log={'train_loss: 0.18537,train_acc:93.254%,F1: 96.670%,Recall:96.667%'}]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val accuracy : 82.270%,val_loss:40.098, F1_score：82.512%, Recall：81.967%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:59<00:00,  5.26it/s, log={'train_loss: 0.16650,train_acc:94.124%,F1: 100.000%,Recall:100.000%'}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val accuracy : 82.715%,val_loss:43.885, F1_score：80.328%, Recall：80.328%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [01:00<00:00,  5.17it/s, log={'train_loss: 0.15302,train_acc:94.504%,F1: 93.333%,Recall:93.333%'}]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val accuracy : 82.324%,val_loss:44.276, F1_score：85.246%, Recall：85.246%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:58<00:00,  5.32it/s, log={'train_loss: 0.13646,train_acc:95.465%,F1: 93.394%,Recall:93.333%'}]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val accuracy : 81.791%,val_loss:47.780, F1_score：80.317%, Recall：80.328%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:58<00:00,  5.34it/s, log={'train_loss: 0.12142,train_acc:96.110%,F1: 100.000%,Recall:100.000%'}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val accuracy : 81.986%,val_loss:50.444, F1_score：88.562%, Recall：88.525%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [01:00<00:00,  5.13it/s, log={'train_loss: 0.11296,train_acc:96.370%,F1: 96.670%,Recall:96.667%'}]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val accuracy : 81.720%,val_loss:51.524, F1_score：86.885%, Recall：86.885%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [01:01<00:00,  5.10it/s, log={'train_loss: 0.09789,train_acc:96.980%,F1: 93.333%,Recall:93.333%'}]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val accuracy : 81.951%,val_loss:53.070, F1_score：86.773%, Recall：86.885%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:57<00:00,  5.45it/s, log={'train_loss: 0.08822,train_acc:97.350%,F1: 96.663%,Recall:96.667%'}]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val accuracy : 82.039%,val_loss:59.408, F1_score：88.449%, Recall：88.525%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:58<00:00,  5.40it/s, log={'train_loss: 0.07638,train_acc:97.900%,F1: 96.620%,Recall:96.667%'}]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val accuracy : 81.364%,val_loss:63.394, F1_score：85.295%, Recall：85.246%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:59<00:00,  5.27it/s, log={'train_loss: 0.06747,train_acc:98.140%,F1: 96.678%,Recall:96.667%'}]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val accuracy : 81.489%,val_loss:62.711, F1_score：88.506%, Recall：88.525%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:57<00:00,  5.43it/s, log={'train_loss: 0.06194,train_acc:98.375%,F1: 100.000%,Recall:100.000%'}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val accuracy : 80.796%,val_loss:72.232, F1_score：78.631%, Recall：78.689%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:55<00:00,  5.62it/s, log={'train_loss: 0.05397,train_acc:98.570%,F1: 96.670%,Recall:96.667%'}]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val accuracy : 80.814%,val_loss:72.696, F1_score：78.677%, Recall：78.689%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:57<00:00,  5.41it/s, log={'train_loss: 0.04741,train_acc:98.820%,F1: 100.000%,Recall:100.000%'}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val accuracy : 81.151%,val_loss:75.984, F1_score：85.238%, Recall：85.246%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:58<00:00,  5.36it/s, log={'train_loss: 0.04864,train_acc:98.705%,F1: 100.000%,Recall:100.000%'}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val accuracy : 80.760%,val_loss:86.008, F1_score：77.137%, Recall：77.049%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:57<00:00,  5.49it/s, log={'train_loss: 0.04512,train_acc:98.830%,F1: 100.000%,Recall:100.000%'}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val accuracy : 80.778%,val_loss:80.108, F1_score：72.267%, Recall：72.131%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [01:03<00:00,  4.96it/s, log={'train_loss: 0.03840,train_acc:99.035%,F1: 100.000%,Recall:100.000%'}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val accuracy : 80.867%,val_loss:79.024, F1_score：83.807%, Recall：83.607%\n"
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import tqdm\n",
    "from nn_DataProcess import prepare_data, build_word2vec, Data_set\n",
    "from sklearn.metrics import confusion_matrix, f1_score, recall_score\n",
    "import os\n",
    "from model import LSTMModel, LSTM_attention\n",
    "from nn_Config import Config\n",
    "from nn_eval import val_accuary\n",
    "\n",
    "\n",
    "def train(train_dataloader, model, device, epoches, lr):\n",
    "    \"\"\"\n",
    "\n",
    "    :param train_dataloader:\n",
    "    :param model:\n",
    "    :param device:\n",
    "    :param epoches:\n",
    "    :param lr:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # 模型为训练模式\n",
    "    model.train()\n",
    "    # 将模型转化到gpu上\n",
    "    model = model.to(device)\n",
    "    print(model)\n",
    "    # 优化器\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    # 损失函数\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.2)  # 学习率调整\n",
    "    best_acc = 0.88\n",
    "    # 一个epoch可以认为是一次训练循环\n",
    "    for epoch in range(epoches):\n",
    "        train_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        # tqdm用在dataloader上其实是对每个batch和batch总数做的进度条\n",
    "        train_dataloader = tqdm.tqdm(train_dataloader)\n",
    "        # train_dataloader.set_description('[%s%04d/%04d %s%f]' % ('Epoch:', epoch + 1, epoches, 'lr:', scheduler.get_last_lr()[0]))\n",
    "        # 遍历每个batch size数据\n",
    "        for i, data_ in (enumerate(train_dataloader)):\n",
    "            # 梯度清零\n",
    "            optimizer.zero_grad()\n",
    "            input_, target = data_[0], data_[1]\n",
    "            # 将数据类型转化为整数\n",
    "            input_ = input_.type(torch.LongTensor)\n",
    "            target = target.type(torch.LongTensor)\n",
    "            # 将数据转换到gpu上\n",
    "            input_ = input_.to(device)\n",
    "            target = target.to(device)\n",
    "            # 前向传播\n",
    "            output = model(input_)\n",
    "            # 扩充维度\n",
    "            target = target.squeeze(1)\n",
    "            # 损失\n",
    "            loss = criterion(output, target)\n",
    "            # 反向传播\n",
    "            loss.backward()\n",
    "            # 梯度更新\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            # print(predicted.shape)\n",
    "            # 计数\n",
    "            total += target.size(0)  # 此处的size()类似numpy的shape: np.shape(train_images)[0]\n",
    "            # print(target.shape)\n",
    "            # 计算预测正确的个数\n",
    "            correct += (predicted == target).sum().item()\n",
    "            # 评价指标F1、Recall、混淆矩阵\n",
    "            F1 = f1_score(target.cpu(), predicted.cpu(), average='weighted')\n",
    "            Recall = recall_score(target.cpu(), predicted.cpu(), average='micro')\n",
    "            # CM=confusion_matrix(target.cpu(),predicted.cpu())\n",
    "            postfix = {'train_loss: {:.5f},train_acc:{:.3f}%'\n",
    "                       ',F1: {:.3f}%,Recall:{:.3f}%'.format(train_loss / (i + 1),\n",
    "                                                            100 * correct / total, 100 * F1, 100 * Recall)}\n",
    "            # tqdm pbar.set_postfix：设置训练时的输出\n",
    "            train_dataloader.set_postfix(log=postfix)\n",
    "\n",
    "        # 计算验证集的准确率\n",
    "        acc = val_accuary(model, val_dataloader, device, criterion)\n",
    "        # 当准确率提升时，保存模型。\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            if os.path.exists(Config.model_state_dict_path) == False:\n",
    "                os.mkdir(Config.model_state_dict_path)\n",
    "            save_path = '{}_epoch_{}.pkl'.format(\"nn_model\", epoch)\n",
    "            print(os.path.join(Config.model_state_dict_path, save_path))\n",
    "            torch.save(model, os.path.join(Config.model_state_dict_path, save_path))\n",
    "        # 恢复到训练模式\n",
    "        model.train()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    splist = []\n",
    "    # 构建word2id词典\n",
    "    word2id = {}\n",
    "    with open(Config.word2id_path, encoding='utf-8') as f:\n",
    "        for line in f.readlines():\n",
    "            sp = line.strip().split()  # 去掉\\n \\t 等\n",
    "            splist.append(sp)\n",
    "        word2id = dict(splist)  # 转成字典\n",
    "\n",
    "    # 转换索引的数据类型为整数\n",
    "    for key in word2id:\n",
    "        word2id[key] = int(word2id[key])\n",
    "\n",
    "    # 构建id2word\n",
    "    id2word = {}\n",
    "    for key, val in word2id.items():\n",
    "        id2word[val] = key\n",
    "\n",
    "    # 设备\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # 得到数字索引表示的句子和标签\n",
    "    train_array, train_lable, val_array, val_lable, test_array, test_lable = prepare_data(word2id,\n",
    "                                                                                          train_path=Config.train_path,\n",
    "                                                                                          val_path=Config.val_path,\n",
    "                                                                                          test_path=Config.test_path,\n",
    "                                                                                          seq_lenth=Config.max_sen_len)\n",
    "    # 构建训练Data_set与DataLoader\n",
    "    train_loader = Data_set(train_array, train_lable)\n",
    "    train_dataloader = DataLoader(train_loader,\n",
    "                                  batch_size=Config.batch_size,\n",
    "                                  shuffle=True,\n",
    "                                  num_workers=0)  # 用了workers反而变慢了\n",
    "    # 构建验证Data_set与DataLoader\n",
    "    val_loader = Data_set(val_array, val_lable)\n",
    "    val_dataloader = DataLoader(val_loader,\n",
    "                                batch_size=Config.batch_size,\n",
    "                                shuffle=True,\n",
    "                                num_workers=0)\n",
    "\n",
    "    # 构建测试Data_set与DataLoader\n",
    "    test_loader = Data_set(test_array, test_lable)\n",
    "    test_dataloader = DataLoader(test_loader,\n",
    "                                 batch_size=Config.batch_size,\n",
    "                                 shuffle=True,\n",
    "                                 num_workers=0)\n",
    "    # 构建word2vec词向量\n",
    "    w2vec = build_word2vec(Config.pre_word2vec_path, word2id, None)\n",
    "    # 将词向量转化为Tensor\n",
    "    w2vec = torch.from_numpy(w2vec)\n",
    "    # CUDA接受float32，不接受float64\n",
    "    w2vec = w2vec.float()\n",
    "    # LSTM_attention\n",
    "    model = LSTM_attention(Config.vocab_size, Config.embedding_dim, w2vec, Config.update_w2v,\n",
    "                           Config.hidden_dim, Config.num_layers, Config.drop_keep_prob, Config.n_class,\n",
    "                           Config.bidirectional)\n",
    "\n",
    "    # 训练\n",
    "    train(train_dataloader, model=model, device=device, epoches=Config.n_epoch, lr=Config.lr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

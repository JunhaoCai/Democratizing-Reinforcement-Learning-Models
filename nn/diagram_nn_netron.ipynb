{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-07-17T15:10:37.705746Z",
     "start_time": "2023-07-17T15:10:36.485345Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "from nn_DataProcess import build_word2vec\n",
    "from nn_Config import Config\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    splist = []\n",
    "    # 构建word2id词典\n",
    "    word2id = {}\n",
    "    with open(Config.word2id_path, encoding='utf-8') as f:\n",
    "        for line in f.readlines():\n",
    "            sp = line.strip().split()  # 去掉\\n \\t 等\n",
    "            splist.append(sp)\n",
    "        word2id = dict(splist)  # 转成字典\n",
    "\n",
    "    # 转换索引的数据类型为整数\n",
    "    for key in word2id:\n",
    "        word2id[key] = int(word2id[key])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/opt/anaconda3/envs/Pytorch/lib/python3.8/site-packages/torch/onnx/symbolic_opset9.py:3227: UserWarning: Exporting a model to ONNX with a batch_size other than 1, with a variable length with LSTM can cause an error when running the ONNX model with a different batch size. Make sure to save the model with a batch size of 1, or define the initial states (h0/c0) as inputs of the model. \n",
      "  warnings.warn(\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving 'lstm_attention.onnx' at http://localhost:8080\n"
     ]
    },
    {
     "data": {
      "text/plain": "('localhost', 8080)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import netron\n",
    "from model import LSTM_attention\n",
    "from nn_Config import Config\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 构建word2vec词向量\n",
    "w2vec = build_word2vec(Config.pre_word2vec_path, word2id, None)\n",
    "# 将词向量转化为Tensor\n",
    "w2vec = torch.from_numpy(w2vec)\n",
    "# CUDA接受float32，不接受float64\n",
    "w2vec = w2vec.float()\n",
    "\n",
    "# LSTM_attention\n",
    "model = LSTM_attention(Config.vocab_size, Config.embedding_dim, w2vec, Config.update_w2v,\n",
    "                       Config.hidden_dim, Config.num_layers, Config.drop_keep_prob, Config.n_class,\n",
    "                       Config.bidirectional)\n",
    "\n",
    "# 创建一个示例输入\n",
    "input_example = torch.zeros((19998, 65), dtype=torch.long)\n",
    "\n",
    "# 将模型转移到指定设备上\n",
    "model = model.to(device)\n",
    "\n",
    "# 将模型保存为ONNX格式\n",
    "torch.onnx.export(model, input_example, \"lstm_attention.onnx\", export_params=True)\n",
    "\n",
    "# 使用netron打开模型结构\n",
    "netron.start(\"lstm_attention.onnx\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-17T14:08:50.489767Z",
     "start_time": "2023-07-17T14:06:39.966730Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
